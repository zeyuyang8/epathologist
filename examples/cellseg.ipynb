{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import cellseg_models_pytorch as csmp\n",
    "from pathlib import Path\n",
    "from cellseg_models_pytorch.datamodules import LizardDataModule\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from cellseg_models_pytorch.training.lit import SegmentationExperiment\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATA_PATH = './data/benchmarks/'\n",
    "DATA_PATH = Path(DATA_PATH)\n",
    "LIZARD_PATH = DATA_PATH / 'lizard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lizard_data():\n",
    "    \"\"\"Prepare lizard data for training, validation, and testing.\"\"\"\n",
    "    fold_split = {\"train\": 1, \"valid\": 2, \"test\": 3}\n",
    "    lizard_module = LizardDataModule(\n",
    "        save_dir=LIZARD_PATH,\n",
    "        fold_split=fold_split,\n",
    "        inst_transforms=[\"cellpose\"],\n",
    "        img_transforms=[\"blur\", \"hue_sat\"],\n",
    "        patch_size=(320, 320),\n",
    "        stride=220,\n",
    "        normalization=\"minmax\",\n",
    "    )\n",
    "    lizard_module.prepare_data()\n",
    "    return lizard_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lizard_data_samples(img_dir, mask_dir, indices):\n",
    "    \"\"\"Plot Lizard data sample\"\"\"\n",
    "    imgs = sorted(img_dir.glob(\"*\"))\n",
    "    masks = sorted(mask_dir.glob(\"*\"))\n",
    "    fig, axes = plt.subplots(3, len(indices)) \n",
    "    for idx, indice in enumerate(indices):\n",
    "        img = csmp.utils.FileHandler.read_img(imgs[indice])\n",
    "        mask = csmp.utils.FileHandler.read_mat(masks[indice], return_all=True)\n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 1].imshow(label2rgb(mask[\"inst_map\"], bg_label=0))\n",
    "        axes[idx, 2].imshow(label2rgb(mask[\"type_map\"], bg_label=0))\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_axis_off()\n",
    "    return fig\n",
    "\n",
    "def test_plot_lizard_data_samples():\n",
    "    _ = plot_lizard_data_samples(\n",
    "        LIZARD_PATH / \"train\" / \"train_im_patches\",\n",
    "        LIZARD_PATH / \"train\" / \"train_mask_patches\",\n",
    "        [0, 50, 300]\n",
    "    )\n",
    "\n",
    "# test_plot_lizard_data_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cellpose_model(enc_name, num_classes):\n",
    "    \"\"\"Get cellpose model\n",
    "    enc_name (str): name of encoder. e.g. -> \"tf_efficientnetv2_s\"\n",
    "    num_classes (int): number of classes. e.g. -> len(lizard_module.type_classes)\n",
    "    \"\"\"\n",
    "    model = csmp.models.cellpose_base(\n",
    "        enc_name=enc_name,\n",
    "        type_classes=num_classes,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_seg_experiment(model):\n",
    "    experiment = SegmentationExperiment(\n",
    "        model=model,\n",
    "        branch_losses={\"cellpose\": \"ssim_mse\", \"type\": \"tversky_focal\"},\n",
    "        branch_metrics={\"cellpose\": [None], \"type\": [\"miou\"]},\n",
    "        optimizer=\"adamw\",\n",
    "    )\n",
    "    return experiment\n",
    "\n",
    "def get_trainer(max_epochs=10):\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        max_epochs=max_epochs,\n",
    "        move_metrics_to_cpu=True,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "def train_model(experiment, trainer, datamodule, ckpt_path=None):\n",
    "    if ckpt_path is None:\n",
    "        trainer.fit(experiment, datamodule=datamodule)\n",
    "        return None\n",
    "    trainer.fit(experiment, \n",
    "                datamodule=datamodule, \n",
    "                ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lizard_cellpose_pipline(ckpt_path=None):\n",
    "    # prepare data\n",
    "    lizard_module = prepare_lizard_data()\n",
    "    model = get_cellpose_model(\"tf_efficientnetv2_s\", \n",
    "                               len(lizard_module.type_classes))\n",
    "    experiment = get_seg_experiment(model)\n",
    "    trainer = get_trainer()\n",
    "    train_model(experiment, \n",
    "                trainer, \n",
    "                lizard_module, \n",
    "                ckpt_path)\n",
    "\n",
    "# lizard_cellpose_pipline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lizard_cellpose(ckpt_path):\n",
    "    model = get_cellpose_model(\"tf_efficientnetv2_s\", 7)\n",
    "    experiment = get_seg_experiment(model)\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    experiment.load_state_dict(ckpt[\"state_dict\"])\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(experiment, input_path):\n",
    "    inferer = csmp.inference.SlidingWindowInferer(\n",
    "        model=experiment,\n",
    "        input_path=input_path,\n",
    "        out_activations={\"cellpose\": None, \"type\": \"softmax\"},\n",
    "        out_boundary_weights={\"cellpose\": True, \"type\": False},\n",
    "        padding=16,\n",
    "        stride=48,\n",
    "        patch_size=(64, 64),\n",
    "        instance_postproc=\"cellpose\",\n",
    "        normalization=\"minmax\",  # same normalization as during training\n",
    "        batch_size=1,  # Set to 1 since input images have different shapes\n",
    "        n_images=3,  # Use only the 3 first images of the folder\n",
    "    )\n",
    "    inferer.infer()\n",
    "    return inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(inferer, input_path, idx):\n",
    "    samples = list(inferer.out_masks.keys())\n",
    "    masks = inferer.out_masks[samples[idx]]\n",
    "    print(len(np.unique(masks[\"inst\"])))\n",
    "    print(np.unique(masks[\"type\"]))\n",
    "    img_path = str(input_path) + f\"/{samples[idx]}.png\"\n",
    "    img = csmp.utils.FileHandler.read_img(img_path)\n",
    "    cont = csmp.utils.draw_thing_contours(masks[\"inst\"], img, masks[\"type\"])\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cont)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cellpose():\n",
    "    cellpose_experiment = load_lizard_cellpose(\n",
    "        './lightning_logs/version_0/checkpoints/epoch=9-step=1540.ckpt'\n",
    "    )\n",
    "    print(\"Infering on lizard data\")\n",
    "    target_path = LIZARD_PATH / \"train\" / \"images\"\n",
    "    inferer = infer(cellpose_experiment, target_path)\n",
    "    _ = plot_contour(inferer, target_path, 0)\n",
    "    \n",
    "    print(\"Infering on TCGA data\")\n",
    "    tcga_path = \"./data/benchmarks/QC/rgb\"\n",
    "    tcga_interer = infer(cellpose_experiment, tcga_path)\n",
    "    _ = plot_contour(tcga_interer, tcga_path, 0)\n",
    "\n",
    "# test_cellpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io\n",
    "\n",
    "# masks = scipy.io.loadmat('./data/benchmarks/lizard/train/labels/crag_2.mat')\n",
    "# print(masks.keys())\n",
    "# masks[\"inst_map\"], masks[\"id\"], masks['class'], masks['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks['centroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epathologist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
