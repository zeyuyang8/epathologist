{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from livelossplot import PlotLosses\n",
    "from src.data.transforms import get_transform\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path, extension):\n",
    "    \"\"\"Returns a sorted list of file names that match the \n",
    "    specified file extension in the given directory.\n",
    "    \"\"\"\n",
    "    file_names = []\n",
    "    # Get file names of files with the correct extnesion\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(extension):\n",
    "            file_names.append(os.path.join(path, file))\n",
    "    return sorted(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, transforms):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Load mask\n",
    "        mask_data = scipy.io.loadmat(mask_path)\n",
    "        mask = mask_data[\"inst_map\"]\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "        \n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        masks_filtered = []\n",
    "        # Skip images with no objects\n",
    "        for i in range(num_objs):\n",
    "            pos = np.nonzero(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            if xmin == xmax or ymin == ymax:\n",
    "                continue\n",
    "            else:\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(mask_data['class'])\n",
    "                masks_filtered.append(masks[i])\n",
    "                \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = np.array(labels)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64).view(-1)\n",
    "        masks_filtered = np.array(masks_filtered).astype(int)\n",
    "        masks_filtered = torch.as_tensor(masks_filtered, dtype=torch.int64)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        \n",
    "        # target is a dictionary containing all the information we have just gathered\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks_filtered\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def od_collate_fn(batch):\n",
    "    ''' \n",
    "    Stack images and targets in batches of consistant size and shape for object detection.\n",
    "\n",
    "    Args:\n",
    "        batch: List of (image, target) tuples.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of stacked images and targets.\n",
    "    '''\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_od_dataloader(img_paths, csv_paths, transform, batch_size, shuffle):\n",
    "    '''Returns a dataloader for object detection.'''\n",
    "    od_dataset = ObjectDetectionDataset(img_paths, csv_paths, transform)\n",
    "\n",
    "    # Create PyTorch DataLoader for Object Detection\n",
    "    od_dataloader = torch.utils.data.DataLoader(od_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=shuffle,\n",
    "                                                collate_fn=od_collate_fn)\n",
    "    return od_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\", \n",
    "                                                               weights_backbone=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sgd_optim(model, lr, momentum=0.9, weight_decay=0.0005):\n",
    "    \"\"\"Returns a stochastic gradient descent (SGD) optimizer associated with the input model, with entered hyperparameters.\n",
    "    Used for training the detection and classification models.\n",
    "    \"\"\"\n",
    "    # Filter model parameters that need to have gradients computed\n",
    "    params = [param for param in model.parameters() if param.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_od_loss(model, loss_fn, dataloader, device):\n",
    "    '''\n",
    "    Returns loss for an object detection model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (Torch object): Torch object detection model\n",
    "        loss_fn (function): Loss function TODO: customize and use loss_fn in the future\n",
    "        dataloader: DataLoader\n",
    "        device (str): Device to run training on ('cpu' or 'cuda')\n",
    "\n",
    "    Returns:\n",
    "        Loss for an object detection model on a given dataset.\n",
    "    '''\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_id, (images, targets) in enumerate(dataloader):\n",
    "            # move data to device\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss += losses.item()\n",
    "    loss = loss / len(dataloader)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_detector(model, optimizer, loss_fn, n_epochs,\n",
    "                   trainloader, valloader,\n",
    "                   device,\n",
    "                   save_path, name):\n",
    "    '''\n",
    "    Trains a detector model for object detection using the specified optimizer, loss function, and training/validation data loaders.\n",
    "\n",
    "    Input:\n",
    "        model (torch object): The detector model to train.\n",
    "        optimizer (function): The optimizer to use for training.\n",
    "        loss_fn (function): The loss function to use for training.\n",
    "        n_epochs (int): The number of epochs to train for.\n",
    "        trainloader (dataloader): The data loader for the training set.\n",
    "        valloader (dataloader): The data loader for the validation set.\n",
    "        device (str): The device to use for training and inference.\n",
    "        save_path (str): The path to save the best model.\n",
    "        name (str): The name of the model.\n",
    "\n",
    "    Output:\n",
    "        A tuple of four numpy arrays containing the training loss, validation loss, training statistics, and validation statistics.\n",
    "    '''\n",
    "    # create save path\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # initialize variables\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    best_val_loss = float('inf')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # plot live loss\n",
    "    liveloss = PlotLosses()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        logs = {}\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_id, (images, targets) in enumerate(trainloader):\n",
    "            # move data to device\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            train_loss += losses.item()\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # evaluate model\n",
    "        train_loss /= len(trainloader)\n",
    "        logs['loss'] = train_loss\n",
    "        val_loss = get_od_loss(model, loss_fn, valloader, device)\n",
    "        logs['val_loss'] = val_loss\n",
    "\n",
    "        # record evaluation metrics\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        # save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model, save_path + name + '.pt')\n",
    "\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train():\n",
    "    train_img_files = get_file_names(\"./data/benchmarks/NuCLS-split/train/rgb/\", 'png')\n",
    "    train_mask_files = get_file_names(\"./data/benchmarks/NuCLS-split/train/mask_mat/\", 'mat')\n",
    "    val_img_files = get_file_names(\"./data/benchmarks/NuCLS-split/val/rgb/\", 'png')\n",
    "    val_mask_files = get_file_names(\"./data/benchmarks/NuCLS-split/val/mask_mat/\", 'mat')\n",
    "    \n",
    "    trainloader = get_od_dataloader(train_img_files, train_mask_files, get_transform(train=True), 8, True)\n",
    "    valloader = get_od_dataloader(val_img_files, val_mask_files, get_transform(train=False), 8, False)\n",
    "    \n",
    "    model = get_model_instance_segmentation(15)\n",
    "    optimizer = get_sgd_optim(model, 0.01)\n",
    "    \n",
    "    # Train the model\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    results = train_detector(\n",
    "        model,\n",
    "        optimizer,\n",
    "        None,  # TODO: add customized loss function\n",
    "        200,\n",
    "        trainloader,\n",
    "        valloader,\n",
    "        device,\n",
    "        './data/checkpoints/',\n",
    "        'maskrcnn_nucls'\n",
    "    )\n",
    "    with open('./data/maskrcnn_nucls_results.pkl', 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "test_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epathologist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
